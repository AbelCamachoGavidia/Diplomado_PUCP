{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 4\n",
    "\n",
    "This assigment will be graded if everything works well. I will run the script as once and everything should be done without errors and mistakes. I should be able to run your scripts in my computer and get all the results. **USE RELATIVE PATHS**. An error or exception or anything that breaks the code will means NO GRADE (0). Additionally, you are not able to modify any file handly. It also means NO GRADE (0). Comment everything you think will help others read your script. We expect 0 errors using GitHub. Everything will be graded!\n",
    "\n",
    "**ASK EVERYTHING! WE ARE HERE TO HELP YOU!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this path **..\\_data\\sbs\\B_RawData\\bancos** you will find scraped data from [this link](https://www.sbs.gob.pe/app/pp/EstadisticasSAEEPortal/Paginas/TIActivaTipoCreditoEmpresa.aspx?tip=B). We get all the information of the last available day of every each month.\n",
    "\n",
    "1. Import all the data and generate a column named as `date_info` that should have the day to information corresponds.\n",
    "2. Append all this datasets and generate a unique dataframe. This newdataset should have information at `rate interest` and `date` level. The columns should be the name of the banks. Be careful since not all the excel files have the same format. **It is totally prohibited to manipulate manually the excel files. This kind of action means NO GRADE on this project.**\n",
    "3. What are the top 5 banks each year with the highest interest rate at `Préstamos hipotecarios para vivienda`, `Consumo -\n",
    "Tarjetas de Crédito`. Present a dataframe with these variables: `year`, `rate_concept`, `banks`, `rate_value`.\n",
    "4. We want to save this dataset in the folder **_output/sbs/group_#**, but we want to save a file per bank. We want to have the information disaggregated at the bank level. Please, save your files with the name of the bank. Avoid blank spaces and use only lowercase letters. Generate the folder of your group using python code. **Hint: os library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the packages as required.\n",
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import all the data and generate a column named as date_info that should have the day to information corresponds.\n",
    "path = r\"../../_data\\sbs\\B_RawData\\bancos\"\n",
    "file_list = [os.path.join(path, file) for file in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar la lectura de los archivos y guardarlos en un diccionario llamado \"excel_dict\"\n",
    "excel_dict = {}\n",
    "for file in file_list:\n",
    "    df = pd.read_excel(file)\n",
    "    # generate a column named as date_info\n",
    "    df[\"date_info\"] = os.path.splitext(file)[0][-9:]\n",
    "    df_final = df_final.append(df)\n",
    "    # guardar todos los archivos en un diccionario según su nombre\n",
    "    file_name = os.path.splitext(file)[0][-21:]\n",
    "    excel_dict[file_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los dataframe contenidos en el diccionario\n",
    "excel_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     26_2_2004\n",
       "1     26_2_2004\n",
       "2     26_2_2004\n",
       "3     26_2_2004\n",
       "4     26_2_2004\n",
       "5     26_2_2004\n",
       "6     26_2_2004\n",
       "7     26_2_2004\n",
       "8     26_2_2004\n",
       "9     26_2_2004\n",
       "10    26_2_2004\n",
       "11    26_2_2004\n",
       "12    26_2_2004\n",
       "13    26_2_2004\n",
       "14    26_2_2004\n",
       "15    26_2_2004\n",
       "16    26_2_2004\n",
       "Name: date_info, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobar que se creo la variable \"date_info\" en cada dataframe\n",
    "excel_dict[\"table_clean_26_2_2004\"][\"date_info\"]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

"cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append all the data.\n",
    "all_data = pd.concat(excel_dict.values())\n"
 
   ]
  },
